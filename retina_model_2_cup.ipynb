{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retina_function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Input, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Recall, Precision, Accuracy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage import color\n",
    "from skimage.filters import threshold_minimum, threshold_otsu\n",
    "from livelossplot import PlotLossesKeras  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config =  tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mask from annotated images.\n",
    "### creating folders to hold the mask, and associated images for training, validation and test dataset respectively.\n",
    "\n",
    "##### 1 . Messidor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.getcwd()\n",
    "documents_direc = folder_path\n",
    "\n",
    "# get the images from Messidor dataset\n",
    "retina_images_2 = glob(os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"image*prime.tif\"))\n",
    "retina_masks_2= glob(os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"image*-6.tif\"))\n",
    "\n",
    "# get the images from BinRushed1 dataset\n",
    "retina_images_1 = glob(os.path.join(documents_direc,\"data\",\"BinRushed\",\"BinRushed1-Corrected\",\"image*prime.jpg\"))\n",
    "retina_masks_1 = glob(os.path.join(documents_direc,\"data\",\"BinRushed\",\"BinRushed1-Corrected\",\"image*-6.jpg\"))\n",
    "\n",
    "# merge them together.\n",
    "retina_images_2.extend(retina_images_1)\n",
    "retina_masks_2.extend(retina_masks_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the path of the retina images and ground truth\n",
    "retina_images = natsorted(retina_images_2)\n",
    "retina_masks = natsorted(retina_masks_2)\n",
    "\n",
    "\n",
    "print (\"Total retina_images: {}, and total ground truth images: {}\".\n",
    "       format(len(retina_images),len(retina_masks)))\n",
    "\n",
    "# split the retina_images into train and test images\n",
    "train_ret, test_ret, train_mask, test_mask = train_test_split(\n",
    "       retina_images, retina_masks, test_size=0.1, random_state=56)\n",
    "# further split the train_retina images and train_mask into validation data.\n",
    "# Thus we have both train, validation and test data, making our solution robust.\n",
    "\n",
    "train_ret_, validation_ret, train_mask_, validation_mask = train_test_split(\n",
    "       train_ret, train_mask, test_size=0.25, random_state=56)\n",
    "\n",
    "train_mask_ = natsorted(train_mask_)\n",
    "train_ret_ = natsorted(train_ret_)\n",
    "\n",
    "validation_mask = natsorted(validation_mask)\n",
    "validation_ret = natsorted(validation_ret)\n",
    "\n",
    "test_mask = natsorted(test_mask)\n",
    "test_ret = natsorted(test_ret)\n",
    "\n",
    "# create a new folder to hold the train, test and validation retina_images.\n",
    "retina_train_folder = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"train/retina\")\n",
    "retina_valid_folder = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"valid/retina\")\n",
    "retina_test_folder = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"test/retina\")\n",
    "\n",
    "# create a new folder to hold the optic disc of the train, test and validation retina images\n",
    "############################################################################################\n",
    "mask_train_folder_disc = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_train/disc/retina\")\n",
    "mask_valid_folder_disc = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_valid/disc/retina\")\n",
    "mask_test_folder_disc = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_test/disc/retina\")\n",
    "\n",
    "# create a new folder to hold the optic cup of the train, test and validation retina images\n",
    "############################################################################################\n",
    "mask_train_folder_cup = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_train/cup/retina\")\n",
    "mask_valid_folder_cup = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_valid/cup/retina\")\n",
    "mask_test_folder_cup = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_test/cup/retina\")\n",
    "\n",
    "# call the function to create the folder.\n",
    "create_save_img(train_ret_, retina_train_folder) # train images and folder.\n",
    "create_save_img(validation_ret, retina_valid_folder) # validation images and folder.\n",
    "create_save_img(test_ret, retina_test_folder) # test images and folder.\n",
    "\n",
    "# call the function to create mask for optic disc\n",
    "###########################################################################\n",
    "create_save_optic_disc(train_mask_, mask_train_folder_disc) # train mask and folder.\n",
    "create_save_optic_disc(validation_mask, mask_valid_folder_disc) # validation mask and folder.\n",
    "create_save_optic_disc(test_mask, mask_test_folder_disc) # test mask and folder.\n",
    "\n",
    "# call the function to create mask for optic disc\n",
    "###########################################################################\n",
    "create_save_optic_cup(train_mask_, mask_train_folder_cup) # train mask and folder.\n",
    "create_save_optic_cup(validation_mask, mask_valid_folder_cup) # validation mask and folder.\n",
    "create_save_optic_cup(test_mask, mask_test_folder_cup) # test mask and folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the total number of train, validation and test images along with their masks.\n",
    "print (\"Total retina train images: {}, and total ground truth images: {}\".\n",
    "       format(len(train_ret_),len(train_mask_)))\n",
    "print (\"Total retina validation images: {}, and total ground truth images: {}\".\n",
    "       format(len(validation_ret),len(validation_mask)))\n",
    "print (\"Total retina test images: {}, and total ground truth images: {}\".\n",
    "       format(len(test_ret),len(test_mask)))\n",
    "\n",
    "train = natsorted(glob(os.path.join(retina_train_folder,\"*.*\")))\n",
    "valid = natsorted(glob(os.path.join(retina_valid_folder,\"*.*\")))\n",
    "test = natsorted(glob(os.path.join(retina_test_folder,\"*.*\")))\n",
    "\n",
    "train_mask_cup = natsorted(glob(os.path.join(mask_train_folder_cup,\"*.*\")))\n",
    "train_mask_disc = natsorted(glob(os.path.join(mask_train_folder_disc,\"*.*\")))\n",
    "\n",
    "valid_mask_cup = natsorted(glob(os.path.join(mask_valid_folder_cup,\"*.*\")))\n",
    "valid_mask_disc = natsorted(glob(os.path.join(mask_valid_folder_disc,\"*.*\")))\n",
    "\n",
    "test_mask_cup = natsorted(glob(os.path.join(mask_test_folder_cup,\"*.*\")))\n",
    "test_mask_disc = natsorted(glob(os.path.join(mask_test_folder_disc,\"*.*\")))\n",
    "\n",
    "# processed;\n",
    "roi_1, _ = get_roi(cv.imread(train_mask_[1]))\n",
    "roi_1 = resize_rgb(roi_1)\n",
    "\n",
    "roi_2, _ = get_roi(cv.imread(validation_mask[2]))\n",
    "roi_2 = resize_rgb(roi_2)\n",
    "\n",
    "roi_3, _ = get_roi(cv.imread(test_mask[1]))\n",
    "roi_3 = resize_rgb(roi_3)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=6, ncols=3, figsize=(14,18))\n",
    "show_image(ax[0,0],train_ret_[1],\"Retina Image (train)\")\n",
    "show_image(ax[0,1],validation_ret[2],\"Retina Image (validation)\")\n",
    "show_image(ax[0,2],test_ret[1],\"Retina Image (test)\")\n",
    "\n",
    "show_image(ax[1,0],train_mask_[1],\"Mask Image (train)\")\n",
    "show_image(ax[1,1],validation_mask[2],\"Mask Image (validation)\")\n",
    "show_image(ax[1,2],test_mask[1],\"Mask Image (test)\")\n",
    "\n",
    "show_image_roi(ax[2,0],roi_1,\"Mask Image (train)\")\n",
    "show_image_roi(ax[2,1],roi_2,\"Mask Image (validation)\")\n",
    "show_image_roi(ax[2,2],roi_3,\"Mask Image (test)\")\n",
    "\n",
    "show_image(ax[3,0],train[4],\"Reg. of Interest(train)\")\n",
    "show_image(ax[3,1],valid[4],\"Reg. of Interest (validation)\")\n",
    "show_image(ax[3,2],test[2],\"Reg. of Interest(test)\")\n",
    "\n",
    "show_image(ax[4,0],train_mask_disc[4],\"Optic Disc(train)\")\n",
    "show_image(ax[4,1],valid_mask_disc[4],\"Optic Disc (validation)\")\n",
    "show_image(ax[4,2],test_mask_disc[2],\"Optic Disc (test)\")\n",
    "\n",
    "show_image(ax[5,0],train_mask_cup[4],\"Optic Cup (train)\")\n",
    "show_image(ax[5,1],valid_mask_cup[4],\"Optic Cup (validation)\")\n",
    "show_image(ax[5,2],test_mask_cup[2],\"Optic Cup (test)\")\n",
    "\n",
    "\n",
    "plt.suptitle(\"Retinal Images, Corresponding Mask / Ground Truth Images and Region of Interest\", fontsize=\"14\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "orig, optic_disc, optic_cup = get_images(train, train_mask_disc, train_mask_cup, \n",
    "                                         retina_train_folder, mask_train_folder_disc, mask_train_folder_cup)\n",
    "\n",
    "orig, optic_disc, optic_cup = get_images(valid, valid_mask_disc, valid_mask_cup,\n",
    "                                       retina_valid_folder, mask_valid_folder_disc, mask_valid_folder_cup)\n",
    "\n",
    "orig, optic_disc, optic_cup = get_images(test, test_mask_disc, test_mask_cup,\n",
    "                                       retina_test_folder, mask_test_folder_disc, mask_test_folder_cup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = natsorted(glob(os.path.join(retina_train_folder,\"*.*\")))\n",
    "valid = natsorted(glob(os.path.join(retina_valid_folder,\"*.*\")))\n",
    "test = natsorted(glob(os.path.join(retina_test_folder,\"*.*\")))\n",
    "\n",
    "train_mask_cup = natsorted(glob(os.path.join(mask_train_folder_cup,\"*.*\")))\n",
    "train_mask_disc = natsorted(glob(os.path.join(mask_train_folder_disc,\"*.*\")))\n",
    "\n",
    "valid_mask_cup = natsorted(glob(os.path.join(mask_valid_folder_cup,\"*.*\")))\n",
    "valid_mask_disc = natsorted(glob(os.path.join(mask_valid_folder_disc,\"*.*\")))\n",
    "\n",
    "test_mask_cup = natsorted(glob(os.path.join(mask_test_folder_cup,\"*.*\")))\n",
    "test_mask_disc = natsorted(glob(os.path.join(mask_test_folder_disc,\"*.*\")))\n",
    "\n",
    "# processed;\n",
    "roi_1, _ = get_roi(cv.imread(train_mask_[1]))\n",
    "roi_1 = resize_rgb(roi_1)\n",
    "\n",
    "roi_2, _ = get_roi(cv.imread(validation_mask[2]))\n",
    "roi_2 = resize_rgb(roi_2)\n",
    "\n",
    "roi_3, _ = get_roi(cv.imread(test_mask[1]))\n",
    "roi_3 = resize_rgb(roi_3)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=6, ncols=3, figsize=(14,18))\n",
    "show_image(ax[0,0],train_ret_[1],\"Retina Image (train)\")\n",
    "show_image(ax[0,1],validation_ret[2],\"Retina Image (validation)\")\n",
    "show_image(ax[0,2],test_ret[1],\"Retina Image (test)\")\n",
    "\n",
    "show_image(ax[1,0],train_mask_[1],\"Mask Image (train)\")\n",
    "show_image(ax[1,1],validation_mask[2],\"Mask Image (validation)\")\n",
    "show_image(ax[1,2],test_mask[1],\"Mask Image (test)\")\n",
    "\n",
    "show_image_roi(ax[2,0],roi_1,\"Mask Image (train)\")\n",
    "show_image_roi(ax[2,1],roi_2,\"Mask Image (validation)\")\n",
    "show_image_roi(ax[2,2],roi_3,\"Mask Image (test)\")\n",
    "\n",
    "show_image(ax[3,0],train[4],\"Reg. of Interest(train)\")\n",
    "show_image(ax[3,1],valid[4],\"Reg. of Interest (validation)\")\n",
    "show_image(ax[3,2],test[2],\"Reg. of Interest(test)\")\n",
    "\n",
    "show_image(ax[4,0],train_mask_disc[4],\"Optic Disc(train)\")\n",
    "show_image(ax[4,1],valid_mask_disc[4],\"Optic Disc (validation)\")\n",
    "show_image(ax[4,2],test_mask_disc[2],\"Optic Disc (test)\")\n",
    "\n",
    "show_image(ax[5,0],train_mask_cup[4],\"Optic Cup (train)\")\n",
    "show_image(ax[5,1],valid_mask_cup[4],\"Optic Cup (validation)\")\n",
    "show_image(ax[5,2],test_mask_cup[2],\"Optic Cup (test)\")\n",
    "\n",
    "\n",
    "plt.suptitle(\"Retinal Images, Corresponding Mask / Ground Truth Images and Region of Interest\", fontsize=\"14\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the data plots;\n",
    "\"\"\"\n",
    "This function plots the class distribution of the dataset.\n",
    "This is done for two reasons -> To check if the dataset is imbalance.\n",
    "2 -> To check if we have enough dataset to train and also validate the model before deploying\n",
    "\n",
    ":param axis represents the image to be plotted.\n",
    ":param original represents the original images.\n",
    ":param masked represents the masked images\n",
    ":param title represents the title of the bar plot.\n",
    ":param label_original represents the label for the original images\n",
    ":param label_masks represents the label for the masked images\n",
    "\"\"\"\n",
    "\n",
    "def show_class_distribution(axis, original, masked_disc, masked_cup, title, label_original, label_masked_disc, label_masked_cup): \n",
    "    axis.bar(\"Original\", original, color='r', label= label_original, width=0.7)\n",
    "    axis.bar(\"Masked Disc\", masked_disc, color='g', label= label_masked_disc, width=0.7)\n",
    "    axis.bar(\"Masked Cup\", masked_cup, color='y', label = label_masked_cup, width=0.7)\n",
    "    axis.set_title(title, fontsize=14, fontweight='bold')\n",
    "    axis.set_ylabel(\"length (arbs)\", fontsize=13, fontweight='bold')\n",
    "    axis.set_ylim((0,len(retina_images)+50))\n",
    "    legend = axis.legend()\n",
    "    \n",
    "\n",
    "    ## checking after splitting.\n",
    "fig, ax = plt.subplots(nrows=2,ncols=2, figsize = (16,12))\n",
    "show_class_distribution(ax[0,0], len(train), len(train_mask_disc),len(train_mask_cup), \n",
    "                        \"Class distribution for Train Data Set\", \"Original\", \"Masked Disc\",\"Masked cup\")\n",
    "show_class_distribution(ax[0,1], len(valid), len(valid_mask_disc),len(valid_mask_cup), \n",
    "                        \"Class distribution for Valid Data Set\", \"Original\", \"Masked Disc\",\"Masked cup\")\n",
    "show_class_distribution(ax[1,0], len(test), len(test_mask_disc),len(test_mask_cup), \n",
    "                        \"Class distribution for Test Data Set\", \"Original\", \"Masked Disc\",\"Masked cup\")\n",
    "show_class_distribution(ax[1,1], len(retina_images), len(retina_masks),len(retina_masks), \n",
    "                        \"Class distribution before Split\", \"Original\", \"Masked Disc\",\"Masked cup\")\n",
    "\n",
    "plt.suptitle(\"Checking for balance between actual image and masked data\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# get the length of the datasets\n",
    "print(\"length of training dataset is: {}, and training mask disc is {}, and training mask cup is {}\".\n",
    "      format(len(train), len(train_mask_disc), len(train_mask_cup)))\n",
    "print(\"length of validation dataset is: {}, and validation mask disc is {}, and validation mask cup is {}\".\n",
    "      format(len(valid), len(valid_mask_disc), len(valid_mask_cup)))\n",
    "print(\"length of test dataset is: {}, and test mask disc is {}, and test mask cup is {}\".\n",
    "      format(len(test), len(test_mask_disc), len(test_mask_cup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing- normalizing the data for both train and validation set\n",
    "# modified from: https://stackoverflow.com/questions/58050113/imagedatagenerator-for-semantic-segmentation\n",
    "\n",
    "seed = 56 # to transform image and corresponding mask with same augmentation parameter.\n",
    "IMG_SIZE = (400,400)\n",
    "batch_size = 6\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=45,\n",
    "    height_shift_range=0.2,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.5,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=45,\n",
    "    height_shift_range=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"train\"), \n",
    "    target_size=IMG_SIZE,batch_size= batch_size, class_mode=None,\n",
    "    seed=seed, shuffle=False, subset=\"training\", color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "train_mask_generator_disc = train_datagen.flow_from_directory(\n",
    "    os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_train\",\"disc\")\n",
    "    , target_size=IMG_SIZE,batch_size= batch_size, class_mode=None,\n",
    "    seed=seed, shuffle=False, color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "train_mask_generator_cup = train_datagen.flow_from_directory(\n",
    "    os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_train\",\"cup\")\n",
    "    , target_size=IMG_SIZE,batch_size= batch_size, class_mode=None,\n",
    "    seed=seed, shuffle=False, color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "val_image_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"valid\"), \n",
    "    target_size=IMG_SIZE,batch_size= batch_size, class_mode=None,\n",
    "    seed=seed, shuffle=False, color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "val_mask_generator_disc = train_datagen.flow_from_directory(\n",
    "        os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_valid\",\"disc\"), \n",
    "    target_size=IMG_SIZE,batch_size= batch_size, class_mode=None,\n",
    "    seed=seed, shuffle=False, color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "val_mask_generator_cup = train_datagen.flow_from_directory(\n",
    "        os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"mask_valid\",\"cup\"), \n",
    "    target_size=IMG_SIZE,batch_size= batch_size, class_mode=None,\n",
    "    seed=seed, shuffle=False, color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "# zip both train and validation validators into a single file.\n",
    "train_generator_disc = zip(train_image_generator, train_mask_generator_disc)\n",
    "val_generator_disc = zip(val_image_generator, val_mask_generator_disc)\n",
    "train_generator_cup = zip(train_image_generator, train_mask_generator_cup)\n",
    "val_generator_cup = zip(val_image_generator, val_mask_generator_cup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# create directory to log the model and csv files to\n",
    "log_file = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"files\")\n",
    "create_directory(log_file)\n",
    "\n",
    "# set the model hyperparamteres\n",
    "BATCH = 6\n",
    "learning_rate = 7e-5\n",
    "num_epochs = 200\n",
    "model_path_disc = log_file+\"/retina_model_disc.h5\"\n",
    "csv_path_disc = log_file+\"/data_disc.csv\"\n",
    "\n",
    "model_path_cup = log_file+\"/retina_model_cup.h5\"\n",
    "csv_path_cup = log_file+\"/data_cup.csv\"\n",
    "\n",
    "\n",
    "\n",
    "train_steps = (len(train_ret_)//BATCH)\n",
    "validation_steps = (len(validation_ret)//BATCH)\n",
    "input_shape = (400,400,3)\n",
    "\n",
    "\n",
    "retina_model_disc = build_unet_model(input_shape)\n",
    "retina_model_disc.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "# retinal_cup model\n",
    "retina_model_cup = build_unet_model(input_shape)\n",
    "retina_model_cup.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics = [dice_coef, iou]\n",
    "\n",
    "retina_model_disc.compile(\n",
    "    loss=[dice_loss], optimizer=Adam(learning_rate), metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path_disc, verbose=1, save_best_only=True),\n",
    "    CSVLogger(csv_path_disc),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "    PlotLossesKeras()\n",
    "]\n",
    "\n",
    "history = retina_model_disc.fit(\n",
    "        train_generator_disc,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_generator_disc,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [dice_coef, iou]\n",
    "\n",
    "retina_model_cup.compile(\n",
    "    loss=[dice_loss], optimizer=Adam(learning_rate), metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path_cup, verbose=1, save_best_only=True),\n",
    "    CSVLogger(csv_path_cup),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "    PlotLossesKeras()\n",
    "]\n",
    "\n",
    "history_cup = retina_model_cup.fit(\n",
    "        train_generator_cup,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_generator_cup,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model dice coeficient')\n",
    "plt.ylabel('dice coeficient')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model Dice loss')\n",
    "plt.ylabel('Dice loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_cup.history['dice_coef'])\n",
    "plt.plot(history_cup.history['val_dice_coef'])\n",
    "plt.title('model dice coeficient', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('dice coeficient', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('epoch', fontsize=14, fontweight='bold')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_cup.history['loss'])\n",
    "plt.plot(history_cup.history['val_loss'])\n",
    "plt.title('model Dice loss', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Dice loss', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('epoch', fontsize=14, fontweight='bold')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.segmentation import clear_border, mark_boundaries\n",
    "    \n",
    "def show_image_pred(axis, image, title):\n",
    "       axis.imshow(image, cmap='gray')\n",
    "       axis.axis('off')\n",
    "       axis.set_title(title)\n",
    "        \n",
    "        \n",
    "def pred_and_save(image_, image_mask, save_directory):\n",
    "    scores = []\n",
    "    images = []\n",
    "    dict_score = {}\n",
    "    os.chdir(save_directory)\n",
    "    for a in range(len(image_)):\n",
    "        image = cv.imread(image_[a])\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        img = cv.resize(image, (400,400))\n",
    "        img_yuv = cv.cvtColor(img, cv.COLOR_RGB2YUV)\n",
    "        clahe = cv.createCLAHE(clipLimit=1, tileGridSize=(2,2))\n",
    "        img_yuv[:,:,0] = clahe.apply(img_yuv[:,:,0])\n",
    "        img = cv.cvtColor(img_yuv, cv.COLOR_YUV2RGB)\n",
    "        img_1 = cv.bilateralFilter(img, 9, 75, 75)\n",
    "        img = img_1.copy()\n",
    "\n",
    "        \n",
    "        x = img/255.0\n",
    "        x = x.astype(np.float32)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        y_pred = retina_model_cup.predict(x)[0]\n",
    "        y_pred = np.where(y_pred > 0.5, 1.0, 0.0)\n",
    "\n",
    "        y_pred_ = y_pred.copy()\n",
    "        y_pred = np.squeeze(y_pred, axis=-1)\n",
    "        y_pred = cv.resize(y_pred, (400,400))\n",
    "        kernel = np.ones((65,65), np.uint8)\n",
    "        y_pred = cv.morphologyEx(y_pred, cv.MORPH_CLOSE, kernel)\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "        cv.imwrite(\"prediction-\"+str(a)+\".jpg\", y_pred)\n",
    "        y_true = cv.imread(image_mask[a])\n",
    "        y_true = cv.cvtColor(y_true,cv.COLOR_BGR2GRAY)\n",
    "        y_true = y_true.astype(np.float32)\n",
    "        y_true = y_true/255.\n",
    "        score = dice_coef(y_true, y_pred.astype(np.float32), smooth=1)\n",
    "        scores.append(float(score))\n",
    "        images.append(y_pred)\n",
    "        dict_score[a] = float(score)\n",
    "    return np.mean(scores) * 100, dict_score, images, scores\n",
    "\n",
    "\n",
    "# saving the result to a folder\n",
    "result_train_folder_cup = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"result/train/cup\")\n",
    "result_valid_folder_cup = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"result/valid/cup\")\n",
    "result_test_folder_cup = os.path.join(documents_direc,\"data\",\"MESSIDOR\",\"result/test/cup\")\n",
    "\n",
    "create_directory(result_train_folder_cup)\n",
    "create_directory(result_valid_folder_cup)\n",
    "create_directory(result_test_folder_cup)\n",
    "\n",
    "empty_directory(result_train_folder_cup)\n",
    "empty_directory(result_test_folder_cup)\n",
    "empty_directory(result_valid_folder_cup)\n",
    "\n",
    "\n",
    "# creating directory for optic cup messidor prediction\n",
    "train_score, dict_list_train, images_train, scores_train = pred_and_save(train, train_mask_cup, result_train_folder_cup)\n",
    "valid_score, dict_list_valid, images_valid, scores_valid = pred_and_save(valid, valid_mask_cup, result_valid_folder_cup)\n",
    "test_score, dict_list_test, images_test, scores_test = pred_and_save(test, test_mask_cup, result_test_folder_cup)\n",
    "\n",
    "#\n",
    "dict_list_train= sorted(dict_list_train, reverse=True)[:4]\n",
    "scores_train = sorted(scores_train, reverse=True)[:4]\n",
    "\n",
    "dict_list_valid= sorted(dict_list_valid, reverse=True)[:4]\n",
    "scores_valid = sorted(scores_valid, reverse=True)[:4]\n",
    "\n",
    "dict_list_test= sorted(dict_list_test, reverse=True)[:4]\n",
    "scores_test = sorted(scores_test, reverse=True)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(8,10))\n",
    "r,c = 0,0\n",
    "for b in range(len(dict_list_train)):\n",
    "    if c >= 4:\n",
    "        c = 0\n",
    "    show_image_pred(ax[0,c], images_train[dict_list_train[b]],\n",
    "                    \"Dice Score: \"+str(round(scores_train[b], 2)))\n",
    "    show_image_pred(ax[1,c], images_valid[dict_list_valid[b]],\n",
    "                    \"Dice Score: \"+str(round(scores_valid[b], 2)))\n",
    "    show_image_pred(ax[2,c], images_test[dict_list_test[b]],\n",
    "                    \"Dice Score: \"+str(round(scores_test[b], 2)))\n",
    "\n",
    "    c += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(scores_train))\n",
    "print(dict_list_train)\n",
    "print(len(train))\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(retina_model_disc.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Dice coeficient Score is: {:.2f}\".format(train_score))\n",
    "print(\"Valid Dice coeficient Score is: {:.2f}\".format(valid_score))\n",
    "print(\"Train Dice coeficient Score is: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
